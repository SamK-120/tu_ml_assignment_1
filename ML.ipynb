{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96026f72-5dd3-4ce8-9e1d-0b52638d0359",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35989544-35da-4ce9-9394-cf0516c36876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pickle\n",
    "import sklearn\n",
    "\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cd04f-c5ce-4ad9-a910-56b4b0d3bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HOME\"] = \"C:/Users/Sam/Documents/Python Scripts\";\n",
    "loan_data_trn = os.path.join(os.environ[\"HOME\"], \"loan-10k.lrn.csv\")\n",
    "loan_data_tst = os.path.join(os.environ[\"HOME\"], \"loan-10k.tes.csv\")\n",
    "loan_data_sol = os.path.join(os.environ[\"HOME\"], \"loan-10k.sol.ex.csv\")\n",
    "\n",
    "cancer_data_trn = os.path.join(os.environ[\"HOME\"], \"breast-cancer-diagnostic.shuf.lrn.csv\")\n",
    "cancer_data_tst = os.path.join(os.environ[\"HOME\"], \"breast-cancer-diagnostic.shuf.tes.csv\")\n",
    "cancer_data_sol = os.path.join(os.environ[\"HOME\"], \"breast-cancer-diagnostic.shuf.sol.ex.csv\")\n",
    "\n",
    "default_data = os.path.join(os.environ[\"HOME\"], \"Loan_default.csv\")\n",
    "\n",
    "#_data = os.path.join(os.environ[\"HOME\"], \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f102c-7966-454e-a916-513b2a0608a5",
   "metadata": {},
   "source": [
    "# Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd59bd2-c5de-41cd-83f9-385298384c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingValues(df, cols):\n",
    "    df_cleaned = df.copy()\n",
    "    for i in cols:\n",
    "        missingVals = df_cleaned[col].isna().sum()\n",
    "        df_cleaned = df_cleaned.dropna(subset=[col])\n",
    "    return df_cleaned\n",
    "    \n",
    "def duplicateReduction(df):\n",
    "    df_deduped = df.drop_duplicates()\n",
    "    return df_deduped\n",
    "    \n",
    "def normalization:\n",
    "    \n",
    "   \n",
    "def correlationMatrix(df):\n",
    "    corr_matrix = df.corr().abs() # calculate correlation matrix\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)) # identify duplicates with uppper triangle mask\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.85)] # remove features with correlation value > threshold\n",
    "    df_reduced = df.drop(to_drop, axis=1)\n",
    "    \n",
    "def classBalancing:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba2e5da-6e65-4cfe-a3dc-b1264e671cd1",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32e80c0-736c-408a-b484-7429c3d3267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "# RandomForest\n",
    "\n",
    "# KNN\n",
    "\n",
    "# KMean\n",
    "\n",
    "\n",
    "def train_model(model_type: type, X_train:pd.DataFrame, y_train:pd.DataFrame) -> sklearn.base.ClassifierMixin:\n",
    "    trained_model = None  # sklearn trained model\n",
    "    if model_type.__name__ == 'RandomForestClassifier':\n",
    "        trained_model = model_type(n_estimators=100,random_state=42)\n",
    "    elif model_type.__name__ == 'KNeighborsClassifier':\n",
    "        trained_model = model_type(n_neighbors=5)\n",
    "    elif model_type.__name__ == 'SVC':\n",
    "        trained_model = model_type(criterion='entropy')\n",
    "        \n",
    "    trained_model.fit(X_train, y_train)\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c5262a-23ab-4657-ad01-55565dfd2ac1",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340cab18-468d-47b9-9ac1-b2146b83bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_disruption_type(trained_model: sklearn.base.ClassifierMixin, X_valid:pd.DataFrame) -> np.ndarray:\n",
    "    y_pred = None\n",
    "    y_pred = trained_model.predict(X_valid)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a16f9e-e95c-4fc3-b82a-2a84f89b9bec",
   "metadata": {},
   "source": [
    "# Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff711f97-057c-478c-a190-ed97c0ea5b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "suitable_metrics = []\n",
    "\n",
    "# Confusion matrix\n",
    "def plot_matrix(cm, class_name):\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for Label {class_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, labels):\n",
    "    for class_name in labels:\n",
    "    class_index = data_processed[data_processed['disruption'] == class_name]['class'].iloc[0]\n",
    "    class_cm = cm[class_index, :, :]\n",
    "    plot_matrix(class_cm, class_name)\n",
    "\n",
    "for class_name in labels:\n",
    "    class_index = data_processed[data_processed['disruption'] == class_name]['class'].iloc[0]\n",
    "    class_cm = cm[class_index, :, :]\n",
    "    plot_confusion_matrix(class_cm, class_name)\n",
    "\n",
    "# Precision\n",
    "\n",
    "# F1\n",
    "suitable_metrics.append(f1_score)\n",
    "\n",
    "# Balanced accuracy\n",
    "\n",
    "# Compare metrices\n",
    "def compare_metrics(y_true:pd.DataFrame, y_pred:pd.DataFrame) -> dict:\n",
    "  scores = {} # dict of metric name -> metric value/score\n",
    "  result = {}\n",
    "  metricsList = ['recall_score', 'f1_score', 'precision_score']\n",
    "  for m in suitable_metrics:\n",
    "      if m.__name__ in metricsList:\n",
    "          result = m(y_true, y_pred, average='weighted')\n",
    "      else:\n",
    "          result = m(y_true, y_pred)\n",
    "      scores[m.__name__]= result\n",
    "\n",
    "  return scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
